{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1d5b525-5557-47af-acc1-7cc5f45996eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import h3pandas\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Spark Session Initialization\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Upload H3 Runways\") \\\n",
    "    .config(\"spark.log.level\", \"ERROR\")\\\n",
    "    .config(\"spark.ui.showConsoleProgress\", \"false\")\\\n",
    "    .config(\"spark.hadoop.fs.azure.ext.cab.required.group\", \"eur-app-aiu\") \\\n",
    "    .config(\"spark.kerberos.access.hadoopFileSystems\", \"abfs://storage-fs@cdpdllive.dfs.core.windows.net/data/project/aiu.db/unmanaged\") \\\n",
    "    .config(\"spark.driver.cores\", \"1\") \\\n",
    "    .config(\"spark.driver.memory\", \"8G\") \\\n",
    "    .config(\"spark.executor.memory\", \"6G\") \\\n",
    "    .config(\"spark.executor.cores\", \"1\") \\\n",
    "    .config(\"spark.executor.instances\", \"2\") \\\n",
    "    .config(\"spark.dynamicAllocation.maxExecutors\", \"6\") \\\n",
    "    .config(\"spark.network.timeout\", \"800s\") \\\n",
    "    .config(\"spark.executor.heartbeatInterval\", \"400s\") \\\n",
    "    .enableHiveSupport() \\\n",
    "    .getOrCreate()\n",
    "\n",
    "def preprocess_rwy_data(df):\n",
    "    columns = ['airport_ident', 'le_ident', 'le_heading_degT',\n",
    "           'he_ident', 'he_heading_degT', 'gate_id', 'hex_id', 'gate_id_nr']\n",
    "    df = df[columns]\n",
    "    df = df.set_index('hex_id')\n",
    "    df = df.h3.h3_get_resolution()\n",
    "    df = df.h3.h3_to_geo()\n",
    "    df['hex_lon'] = df.geometry.apply(lambda l:l.x)\n",
    "    df['hex_lat'] = df.geometry.apply(lambda l:l.y)\n",
    "    df = df.drop(['geometry'],axis=1).reset_index()\n",
    "    df = df.rename({'h3_resolution':'hex_res'}, axis=1)\n",
    "    reorder_cols = ['airport_ident', 'le_ident', 'le_heading_degT',\n",
    "           'he_ident', 'he_heading_degT', 'hex_id', 'hex_res', 'hex_lon', 'hex_lat', 'gate_id', 'gate_id_nr']\n",
    "    return(df[reorder_cols])\n",
    "\n",
    "\n",
    "def load_rwy_data_to_dl(spark, pdf, project, table):\n",
    "    sdf = spark.createDataFrame(pdf)\n",
    "    sdf.write.mode(\"append\").insertInto(f\"`{project}`.`{table}`\")\n",
    "    return None\n",
    "\n",
    "rwy_files_path = 'runway_hex'\n",
    "rwy_files = [f for f in listdir(rwy_files_path) if isfile(join(rwy_files_path, f))]\n",
    "\n",
    "for filename in rwy_files: \n",
    "    print(f\"Processing file: {filename}\")\n",
    "    \n",
    "    # Extract\n",
    "    pdf = pd.read_parquet(f'{rwy_files_path}/{filename}')\n",
    "    \n",
    "    # Transform\n",
    "    pdf = preprocess_rwy_data(pdf)\n",
    "\n",
    "    # Load\n",
    "    load_rwy_data_to_dl(spark, pdf, project = 'project_aiu', table = 'opdi_runway_hexagons')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
