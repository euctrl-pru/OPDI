{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abbfb807-bdbd-4fbd-9ab2-0cfa619ce032",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import traffic\n",
    "from traffic.data import opensky\n",
    "import h3\n",
    "\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "# Trajectories\n",
    "df = pd.read_parquet('../data/2023-08-02-11.parquet')\n",
    "df['id'] = df['icao24'] + '-' + df['callsign'] + '-' + df['time'].dt.date.apply(str)\n",
    "df = df[['id', 'time', 'icao24', 'callsign', 'lat', 'lon', 'baroaltitude']]\n",
    "\n",
    "# Add hex_ids \n",
    "\n",
    "df['hex_id_5'] = df.apply(lambda l:h3.geo_to_h3(l['lat'],l['lon'], 5),axis=1)\n",
    "df['hex_id_11'] = df.apply(lambda l:h3.geo_to_h3(l['lat'],l['lon'], 11),axis=1)\n",
    "\n",
    "# Convert altitudes to ft and FL\n",
    "baroaltitude'\n",
    "df['baroaltitude_ft'] = df['baroaltitude']*3.28084\n",
    "df['baroaltitude_fl'] = df['baroaltitude']*3.28084/100\n",
    "\n",
    "# Filter out low altitude statevectors\n",
    "\n",
    "df_low = df[df['baroaltitude_ft'] < 5000] \n",
    "\n",
    "# Read airport_hexagonifications\n",
    "\n",
    "apt_hex = pd.read_parquet('../data/airport_hex/airport_hex_res_5.parquet')\n",
    "apt_hex = apt_hex[apt_hex['type']=='large_airport']\n",
    "\n",
    "# Create list of possible arrival / departure airports\n",
    "arr_dep_apt = df_low.merge(apt_hex, left_on='hex_id_5', right_on='hex_id', how='inner')\n",
    "arr_dep_apt = arr_dep_apt.groupby('id_x')['ident'].apply(set).reset_index()\n",
    "arr_dep_apt['ident'] = arr_dep_apt['ident'].apply(list)\n",
    "arr_dep_apt = arr_dep_apt.rename({'id_x':'id', 'ident':'potential_apt'},axis=1)\n",
    "\n",
    "df_low = df_low.merge(arr_dep_apt, on = 'id', how = 'left')\n",
    "id_example = '4009d8-BAW3ET-2023-08-02' \n",
    "apts_example = ['EGLL', 'EHAM']\n",
    "\n",
    "def tracks_to_hex(df_low, id_example, apts_example):\n",
    "    #print(df_low)\n",
    "    #print(id_example)\n",
    "    #print(apts_example)\n",
    "    df_single = df_low[df_low['id'] == id_example]\n",
    "\n",
    "    core_cols_single = ['id', 'time', 'lat', 'lon', 'hex_id_11', 'baroaltitude_fl']\n",
    "\n",
    "    df_single = df_single[core_cols_single]\n",
    "    df_single = df_single.reset_index()\n",
    "\n",
    "    core_cols_rwy = ['id', 'airport_ref', 'airport_ident', 'gate_id', 'hex_id', 'gate_id_nr','le_ident','he_ident']\n",
    "\n",
    "    df_rwys = []\n",
    "\n",
    "    for apt in apts_example:\n",
    "        df_rwy = pd.read_parquet(f'../data/runway_hex/{apt}.parquet')\n",
    "        df_rwys.append(df_rwy)\n",
    "\n",
    "    df_rwys = pd.concat(df_rwys)\n",
    "    df_rwys = df_rwys[core_cols_rwy]\n",
    "\n",
    "    df_hex_rwy = df_single.merge(df_rwys,left_on='hex_id_11', right_on='hex_id', how='left')\n",
    "\n",
    "    result = df_hex_rwy.groupby(['id_x','airport_ident', 'gate_id','le_ident','he_ident'])['time'].agg([min,max]).reset_index().sort_values('min')\n",
    "    return result\n",
    "\n",
    "dfs = arr_dep_apt.apply(lambda l: tracks_to_hex(df_low, l['id'],l['potential_apt']),axis=1).to_list()\n",
    "\n",
    "result = pd.concat(dfs)\n",
    "\n",
    "def clean_gate(gate_id):\n",
    "    if gate_id == 'runway_hexagons':\n",
    "        return 'runway_hexagons',0\n",
    "    else:\n",
    "        return '_'.join(gate_id.split('_')[:4]), int(gate_id.split('_')[4])\n",
    "\n",
    "result['gate_type'], result['gate_distance_from_rwy_nm'] = zip(*result.gate_id.apply(clean_gate))\n",
    "\n",
    "## Determining arrival / departure... \n",
    "\n",
    "result = result.reset_index(drop=True)\n",
    "\n",
    "result_min = result.loc[result.groupby(['id_x', 'airport_ident', 'le_ident', 'he_ident'])['gate_distance_from_rwy_nm'].idxmin()]\n",
    "result_max = result.loc[result.groupby(['id_x', 'airport_ident', 'le_ident', 'he_ident'])['gate_distance_from_rwy_nm'].idxmax()] \n",
    "\n",
    "# Copy the DataFrame to avoid modifying the original unintentionally\n",
    "result_copy = result.copy()\n",
    "\n",
    "# Compute the minimum and maximum 'gate_distance_from_rwy_nm' for each group\n",
    "min_values = result.groupby(['id_x', 'airport_ident', 'le_ident', 'he_ident'])['gate_distance_from_rwy_nm'].transform('min')\n",
    "max_values = result.groupby(['id_x', 'airport_ident', 'le_ident', 'he_ident'])['gate_distance_from_rwy_nm'].transform('max')\n",
    "\n",
    "# Add these as new columns to the DataFrame\n",
    "result_copy['min_gate_distance'] = min_values\n",
    "result_copy['max_gate_distance'] = max_values\n",
    "\n",
    "# Now, you can filter rows where 'gate_distance_from_rwy_nm' matches the min or max values\n",
    "# To specifically keep rows with the minimum value:\n",
    "result_min = result_copy[result_copy['gate_distance_from_rwy_nm'] == result_copy['min_gate_distance']]\n",
    "\n",
    "# To specifically keep rows with the maximum value:\n",
    "result_max = result_copy[result_copy['gate_distance_from_rwy_nm'] == result_copy['max_gate_distance']]\n",
    "\n",
    "cols_of_interest = ['id_x', 'airport_ident', 'le_ident', 'he_ident', 'min', 'gate_distance_from_rwy_nm']\n",
    "result_min = result_min[cols_of_interest].rename({'min':'time_entry_min_distance', 'gate_distance_from_rwy_nm':'min_gate_distance_from_rwy_nm'},axis=1)\n",
    "result_max = result_max[cols_of_interest].rename({'min':'time_entry_max_distance', 'gate_distance_from_rwy_nm':'max_gate_distance_from_rwy_nm'},axis=1)\n",
    "\n",
    "det = result_min.merge(result_max, on=['id_x', 'airport_ident', 'le_ident', 'he_ident'], how='outer')\n",
    "\n",
    "det['time_since_minimum_distance'] = det['time_entry_min_distance']-det['time_entry_max_distance']\n",
    "\n",
    "det['time_since_minimum_distance_s'] = det['time_since_minimum_distance'].dt.total_seconds()\n",
    "\n",
    "det['status'] = det['time_since_minimum_distance_s'].apply(lambda l: 'arrival' if l > 0 else 'departure')\n",
    "det['status'] = det['status'].fillna('undetermined')\n",
    "\n",
    "det = det[['id_x', 'airport_ident', 'le_ident', 'he_ident','status']]\n",
    "\n",
    "gb_cols = ['id_x', 'airport_ident', 'le_ident', 'he_ident', 'gate_type']\n",
    "result = result.groupby(gb_cols).agg(\n",
    "    entry_time_approach_area=('min', 'min'),\n",
    "    exit_time_approach_area=('max', 'max'),\n",
    "    intersected_subsections=('gate_distance_from_rwy_nm', 'count'),\n",
    "    minimal_distance_runway=('gate_distance_from_rwy_nm', 'min'),\n",
    "    maximal_distance_runway=('gate_distance_from_rwy_nm', 'max')\n",
    ")\n",
    "result = result.reset_index()\n",
    "\n",
    "rwy_result_cols = ['id_x', 'airport_ident', 'le_ident', 'he_ident']\n",
    "\n",
    "rwy_result = result[rwy_result_cols + ['gate_type']]\n",
    "rwy_result = rwy_result[rwy_result['gate_type']=='runway_hexagons']\n",
    "rwy_result = rwy_result[rwy_result_cols]\n",
    "rwy_result['runway_detected'] = True\n",
    "\n",
    "result = result.merge(rwy_result, on=rwy_result_cols, how = 'left')\n",
    "\n",
    "result['runway_detected'] = result['runway_detected'].fillna(False)\n",
    "\n",
    "result = result[result['gate_type']!='runway_hexagons']\n",
    "\n",
    "result['high_number_intersections'] = result['intersected_subsections']>5\n",
    "\n",
    "result['low_minimal_distance'] = result['minimal_distance_runway']<5\n",
    "\n",
    "result['touched_closest_segment_to_rw'] = result['minimal_distance_runway']==1\n",
    "\n",
    "result['touched_second_closest_segment_to_rw'] = result['minimal_distance_runway']<=2 \n",
    "\n",
    "approach_detected_weight = 0.3\n",
    "rwy_detected_weight = 2\n",
    "high_number_intersections_weight = 1 \n",
    "low_minimal_distance_weight = 1\n",
    "touched_closest_segment_to_rw_weight = 1.5\n",
    "touched_second_closest_segment_to_rw_weight = 0.75\n",
    "\n",
    "max_score = approach_detected_weight + rwy_detected_weight + high_number_intersections_weight + low_minimal_distance_weight + touched_closest_segment_to_rw_weight + touched_second_closest_segment_to_rw_weight\n",
    "\n",
    "result['score'] = (\n",
    "                   1*approach_detected_weight + # For all flights in this dataset an approach is detected (i.e., they entered the approach cone)\n",
    "                   result['runway_detected'].apply(int)*rwy_detected_weight + \n",
    "                   result['high_number_intersections'].apply(int)*high_number_intersections_weight + \n",
    "                   result['low_minimal_distance'].apply(int)*touched_closest_segment_to_rw_weight + \n",
    "                   result['touched_closest_segment_to_rw'].apply(int)*touched_closest_segment_to_rw_weight + \n",
    "                   result['touched_second_closest_segment_to_rw'].apply(int)*touched_second_closest_segment_to_rw_weight\n",
    "                  ) / max_score * 100\n",
    "\n",
    "result = result.reset_index(drop=True)\n",
    "\n",
    "result = result.merge(det,on=['id_x','airport_ident','le_ident','he_ident'], how ='left')\n",
    "\n",
    "result['status'] = result['status'].fillna('undetermined')\n",
    "\n",
    "result['rwy'] = result['le_ident'] + '/' + result['he_ident']\n",
    "\n",
    "rwy_winner = result.loc[result.groupby(['id_x','airport_ident'])['score'].idxmax()]\n",
    "rwy_winner['score'] = rwy_winner['score'].apply(str)\n",
    "rwy_winner = rwy_winner.groupby(['id_x','airport_ident'])['le_ident', 'he_ident', 'rwy','score', 'status'].agg(', '.join).reset_index()\n",
    "rwy_winner = rwy_winner.rename({\n",
    "    'id_x':'id',\n",
    "    'rwy' : 'likely_rwy',\n",
    "    'score': 'likely_rwy_score',\n",
    "    'status': 'likely_rwy_status'\n",
    "    }, axis=1)\n",
    "\n",
    "id_cols = ['id', 'airport_ident', 'le_ident', 'he_ident']\n",
    "rwy_winner_flag = rwy_winner[id_cols]\n",
    "\n",
    "rwy_winner_flag['winner'] = True\n",
    "\n",
    "result = result.rename({'id_x':'id'}, axis=1)\n",
    "result = result.merge(rwy_winner_flag, on = id_cols, how='left') \n",
    "result['winner'] = result['winner'].fillna(False)\n",
    "\n",
    "rwy_losers = result[result['winner']==False]\n",
    "\n",
    "rwy_losers['score'] = rwy_losers['score'].apply(str)\n",
    "rwy_losers = rwy_losers.groupby(['id','airport_ident'])['le_ident', 'he_ident', 'rwy','score', 'status'].agg(', '.join).reset_index()\n",
    "\n",
    "rwy_losers = rwy_losers.rename({\n",
    "    'rwy' : 'potential_other_rwys',\n",
    "    'score': 'potential_other_rwy_scores',\n",
    "    'status': 'potential_other_rwy_status'\n",
    "    }, axis=1)[['id', 'airport_ident', 'potential_other_rwys', 'potential_other_rwy_scores', 'potential_other_rwy_status']]\n",
    "\n",
    "rwy_determined = rwy_winner.merge(rwy_losers, on=['id','airport_ident'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b5149b-6059-401f-8a91-f55f6b639a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "rwy_determined[~rwy_determined.potential_other_rwys.isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105449f6-bdba-4b8c-b59d-fed8c9a999e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_detect = '3c6dd6-EWG14NR-2023-08-02'\n",
    "rwy_determined_f = rwy_determined[rwy_determined['id'] == id_detect]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b58dfef-059b-4de5-b459-1a88ef271fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df.id == id_detect]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95907dfc-4477-4d55-be60-06beaa1bc20d",
   "metadata": {},
   "outputs": [],
   "source": [
    "result[result['id']==id_detect]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade7e845-9df1-4c0c-80a9-50103324f2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "rwy_determined_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e3f7f4-86af-47b8-af58-89077dcb004d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h3_viz\n",
    "import folium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f8ac0d-a67f-43eb-8df9-2ea800681c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "egll = pd.read_parquet(f'../data/runway_hex/EGLL.parquet')\n",
    "map_viz = h3_viz.choropleth_map(\n",
    "        egll,\n",
    "        column_name='gate_id_nr',\n",
    "        border_color='black',\n",
    "        fill_opacity=0.7,\n",
    "        color_map_name='Reds',\n",
    "        initial_map=None,\n",
    "        initial_location=[df.lat.values[0], df.lon.values[0]],\n",
    "        initial_zoom = 13,\n",
    "        tooltip_columns = ['id', 'airport_ref', 'airport_ident', 'le_ident', 'he_ident', 'length_ft', 'width_ft',\n",
    "   'surface', 'lighted', 'closed', 'gate_id']\n",
    "    )\n",
    "\n",
    "# Function to add a trajectory to the map\n",
    "def add_trajectory(map_object, dataframe):\n",
    "    \"\"\"\n",
    "    Adds an aircraft trajectory to a Folium map based on coordinates in a Pandas DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    - map_object: Folium Map instance where the trajectory will be added.\n",
    "    - dataframe: Pandas DataFrame containing the trajectory coordinates with columns 'lat' and 'lon'.\n",
    "    \"\"\"\n",
    "    # Extracting coordinates from DataFrame\n",
    "    coordinates = dataframe[['lat', 'lon']].values.tolist()\n",
    "    # Adding a PolyLine to the map to represent the trajectory\n",
    "    folium.PolyLine(coordinates, color=\"blue\", weight=2.5, opacity=1).add_to(map_object)\n",
    "\n",
    "# Add the aircraft trajectory to the map\n",
    "add_trajectory(map_viz, df)\n",
    "\n",
    "# Display the map\n",
    "map_viz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e28f0b-f573-4568-aeb4-b7488871c234",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4006b8d-13fc-4e18-9d9d-0c118611329c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rwy_determined['id'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4658f5d6-c0d3-4302-b707-9141bbf11320",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31878fc4-6292-4551-9393-41d44a289b5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "0c82f207-1ab5-4944-b654-3bbdbd552c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import traffic\n",
    "from traffic.data import opensky\n",
    "import h3\n",
    "\n",
    "# Limitation: The current id should represent a flight from ADEP to ADES. If the ID does not represent this, max score vote would mess up the result.\n",
    "# Solution: Create a new ID which checks whether the flight is one flight, otherwise it would detect and split the id in multiple ids.  \n",
    "\n",
    "# Limitation: For each track there is not necessarily and airport found\n",
    "# Solution: Work with larger Radius or Height in airport detection?\n",
    "\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "# Add hex_ids \n",
    "\n",
    "def add_hex_ids(df, longitude_col='lon', latitude_col ='lat', resolutions=[5, 11]):\n",
    "    \"\"\"\n",
    "    Adds hexagonal IDs to the DataFrame for specified resolutions.\n",
    "    \"\"\"\n",
    "    \n",
    "    for res in resolutions:\n",
    "        df[f'hex_id_{res}'] = df.apply(lambda row: h3.geo_to_h3(row[latitude_col], row[longitude_col], res), axis=1)\n",
    "    return df\n",
    "\n",
    "# Convert altitudes to ft and FL\n",
    "\n",
    "def convert_baroalt_in_m_to_ft_and_FL(df, baroaltitude_col = 'baroaltitude'):\n",
    "    \"\"\"\n",
    "    Converts barometric altitudes (in meter) to feet (ft) and flight levels (FL).\n",
    "    \"\"\"\n",
    "    df['baroaltitude_ft'] = df[baroaltitude_col] * 3.28084\n",
    "    df['baroaltitude_fl'] = df['baroaltitude_ft'] / 100\n",
    "    return df\n",
    "\n",
    "# Filter out low altitude statevectors\n",
    "\n",
    "def filter_low_altitude_statevectors(df, baroalt_ft_col = 'baroaltitude_ft', threshold=5000):\n",
    "    \"\"\"\n",
    "    Filters out aircraft states below a specified altitude threshold.\n",
    "    \"\"\"\n",
    "    return df[df[baroalt_ft_col] < threshold]\n",
    "\n",
    "# Read airport_hexagonifications\n",
    "\n",
    "def identify_potential_airports(df, track_id_col = 'id', hex_id_col='hex_id', apt_types = ['large_airport', 'medium_airport']):\n",
    "    \"\"\"\n",
    "    Merges aircraft states with airport data based on hex ID (resolution 5).\n",
    "    \"\"\"\n",
    "    airports_df = pd.read_parquet('../data/airport_hex/airport_hex_res_5.parquet')\n",
    "    airports_df = airports_df[airports_df['type'].isin(apt_types)]\n",
    "\n",
    "    # Create list of possible arrival / departure airports\n",
    "    arr_dep_apt = df.merge(airports_df, left_on='hex_id_5', right_on=hex_id_col, how='left')\n",
    "    arr_dep_apt = arr_dep_apt[~arr_dep_apt['ident'].isna()]\n",
    "    arr_dep_apt = arr_dep_apt.groupby('id_x')['ident'].apply(set).reset_index()\n",
    "    arr_dep_apt['ident'] = arr_dep_apt['ident'].apply(list)\n",
    "    arr_dep_apt = arr_dep_apt.rename({'id_x':'id', 'ident':'potential_apt'},axis=1)\n",
    "\n",
    "    return arr_dep_apt\n",
    "\n",
    "def identify_runways(df, track_id_col = 'id', longitude_col = 'lon', latitude_col = 'lat', baroaltitude_col = 'baroaltitude'):\n",
    "    \n",
    "    df_w_hex = add_hex_ids(df, longitude_col=longitude_col, latitude_col=latitude_col,  resolutions=[5, 11])\n",
    "    \n",
    "    df_w_baroalt_ft_fl = convert_baroalt_in_m_to_ft_and_FL(df_w_hex, baroaltitude_col = baroaltitude_col)\n",
    "    \n",
    "    df_f_low_alt = filter_low_altitude_statevectors(df_w_baroalt_ft_fl, baroalt_ft_col = 'baroaltitude_ft', threshold=25000)\n",
    "    \n",
    "    #df = identify_potential_airports(df_f_low_alt, track_id_col = track_id_col, hex_id_col='hex_id', apt_types = ['large_airport'])\n",
    "\n",
    "    return df_f_low_alt\n",
    "    \n",
    "# Trajectories\n",
    "df = pd.read_parquet('../data/2023-08-02-11.parquet')\n",
    "df['id'] = df['icao24'] + '-' + df['callsign'] + '-' + df['time'].dt.date.apply(str)\n",
    "df = df[['id', 'time', 'icao24', 'callsign', 'lat', 'lon', 'baroaltitude']]\n",
    "\n",
    "df = identify_runways(df)\n",
    "\n",
    "airports_df = pd.read_parquet('../data/airport_hex/airport_hex_res_5.parquet')\n",
    "airports_df = airports_df[airports_df['type'].isin(apt_types)]\n",
    "\n",
    "# Create list of possible arrival / departure airports\n",
    "arr_dep_apt = df.merge(airports_df, left_on='hex_id_5', right_on=hex_id_col, how='left')\n",
    "arr_dep_apt = arr_dep_apt[~arr_dep_apt['ident'].isna()]\n",
    "arr_dep_apt = arr_dep_apt.groupby('id_x')['ident'].apply(set).reset_index()\n",
    "arr_dep_apt['ident'] = arr_dep_apt['ident'].apply(list)\n",
    "arr_dep_apt = arr_dep_apt.rename({'id_x':'id', 'ident':'potential_apt'},axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "b10000a6-2b93-4e60-a651-b42c480918fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_392/1698225101.py:109: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_f_low_alt['time'] = pd.to_datetime(df_f_low_alt['time'])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import traffic\n",
    "from traffic.data import opensky\n",
    "import h3\n",
    "\n",
    "# Limitation: The current id should represent a flight from ADEP to ADES. If the ID does not represent this, max score vote would mess up the result.\n",
    "# Solution: Create a new ID which checks whether the flight is one flight, otherwise it would detect and split the id in multiple ids.  \n",
    "\n",
    "# Limitation: For each track there is not necessarily and airport found\n",
    "# Solution: Work with larger Radius or Height in airport detection?\n",
    "\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "# Add hex_ids \n",
    "def add_statevector_id(df):\n",
    "    \"\"\"\n",
    "    Create a numeric ID for each statevector by using the row index + 1 (to start from 1 instead of 0)\n",
    "    \"\"\"\n",
    "    df['statevector_id'] = range(1, len(df) + 1)\n",
    "    return df\n",
    "\n",
    "\n",
    "def add_hex_ids(df, longitude_col='lon', latitude_col ='lat', resolutions=[5, 11]):\n",
    "    \"\"\"\n",
    "    Adds hexagonal IDs to the DataFrame for specified resolutions.\n",
    "    \"\"\"\n",
    "    \n",
    "    for res in resolutions:\n",
    "        df[f'hex_id_{res}'] = df.apply(lambda row: h3.geo_to_h3(row[latitude_col], row[longitude_col], res), axis=1)\n",
    "    return df\n",
    "\n",
    "# Convert altitudes to ft and FL\n",
    "\n",
    "def convert_baroalt_in_m_to_ft_and_FL(df, baroaltitude_col = 'baroaltitude'):\n",
    "    \"\"\"\n",
    "    Converts barometric altitudes (in meter) to feet (ft) and flight levels (FL).\n",
    "    \"\"\"\n",
    "    df['baroaltitude_ft'] = df[baroaltitude_col] * 3.28084\n",
    "    df['baroaltitude_fl'] = df['baroaltitude_ft'] / 100\n",
    "    return df\n",
    "\n",
    "# Filter out low altitude statevectors\n",
    "\n",
    "def filter_low_altitude_statevectors(df, baroalt_ft_col = 'baroaltitude_ft', threshold=5000):\n",
    "    \"\"\"\n",
    "    Filters out aircraft states below a specified altitude threshold.\n",
    "    \"\"\"\n",
    "    return df[df[baroalt_ft_col] < threshold]\n",
    "\n",
    "# Read airport_hexagonifications\n",
    "\n",
    "def identify_potential_airports(df, track_id_col = 'id', hex_id_col='hex_id', apt_types = ['large_airport', 'medium_airport']):\n",
    "    \"\"\"\n",
    "    Merges aircraft states with airport data based on hex ID (resolution 5).\n",
    "    \"\"\"\n",
    "    \n",
    "    airports_df = pd.read_parquet('../data/airport_hex/airport_hex_res_5.parquet')\n",
    "    airports_df = airports_df[airports_df['type'].isin(apt_types)]\n",
    "    \n",
    "    airports_df = airports_df.rename({'id':'apt_id'},axis=1)\n",
    "    \n",
    "    # Create list of possible arrival / departure airports\n",
    "    arr_dep_apt = df.merge(airports_df, left_on='hex_id_5', right_on=hex_id_col, how='left')\n",
    "\n",
    "    # Convert the 'time' column to datetime format if it's not already\n",
    "    arr_dep_apt['time'] = pd.to_datetime(arr_dep_apt['time'])\n",
    "\n",
    "    # Initialize the 'segment_status' column with an empty string\n",
    "    arr_dep_apt['segment_status'] = ''\n",
    "\n",
    "    # Group by 'id_x' and 'ident'\n",
    "    grouped = arr_dep_apt.groupby([track_id_col, 'ident'])\n",
    "\n",
    "    # For each group, find the index of the min and max time and assign 'start' and 'end' respectively\n",
    "    for name, group in grouped:\n",
    "        start_index = group['time'].idxmin()\n",
    "        end_index = group['time'].idxmax()\n",
    "\n",
    "        # Assign 'start' to the row with the minimum time\n",
    "        arr_dep_apt.at[start_index, 'segment_status'] = 'start'\n",
    "\n",
    "        # Assign 'end' to the row with the maximum time\n",
    "        arr_dep_apt.at[end_index, 'segment_status'] = 'end'\n",
    "\n",
    "    # Step 1: Filter to only include 'start' or 'end'\n",
    "    filtered_df = arr_dep_apt[arr_dep_apt['segment_status'].isin(['start', 'end'])]\n",
    "\n",
    "    # Merge the start and end DataFrames on 'id_x' and 'ident'\n",
    "    apt_detections_df = pd.merge(start_df, end_df, on=[track_id_col, 'ident'], how='outer')\n",
    "\n",
    "    core = [track_id_col, 'ident', 'start_time',  'start_statevector_id', 'end_time', 'end_statevector_id']\n",
    "    apt_detections_df = apt_detections_df[core]\n",
    "\n",
    "    return apt_detections_df\n",
    "\n",
    "\n",
    "def identify_runways_from_low_trajectories(apt_detections_df, df_f_low_alt):\n",
    "\n",
    "    # Step 0: Creation of an ID & renaming cols\n",
    "    apt_detections_df = apt_detections_df.reset_index()\n",
    "    apt_detections_df['apt_detection_id'] = apt_detections_df['id'] + '_' + apt_detections_df['index'].apply(str)\n",
    "    apt_detections_df = apt_detections_df[['id', 'ident', 'start_time', 'end_time', 'apt_detection_id']]\n",
    "    apt_detections_df.columns = ['id', 'apt_det_ident', 'apt_det_start_time', 'apt_det_end_time', 'apt_det_id']\n",
    "\n",
    "    # Step 1: Convert datetime columns to datetime format if they are not already\n",
    "    apt_detections_df['apt_det_start_time'] = pd.to_datetime(apt_detections_df['apt_det_start_time'])\n",
    "    apt_detections_df['apt_det_end_time'] = pd.to_datetime(apt_detections_df['apt_det_end_time'])\n",
    "    df_f_low_alt['time'] = pd.to_datetime(df_f_low_alt['time'])\n",
    "\n",
    "    # Step 2: Merge the data frames on 'id'\n",
    "    merged_df = pd.merge(df_f_low_alt, apt_detections_df, on='id', how='inner')\n",
    "\n",
    "    # Step 3: Filter rows where 'time' is between 'apt_det_start_time' and 'apt_det_end_time'\n",
    "    result_df = merged_df[(merged_df['time'] >= merged_df['apt_det_start_time']) & \n",
    "                          (merged_df['time'] <= merged_df['apt_det_end_time'])]\n",
    "    \n",
    "    # Step 5: Match with runways\n",
    "\n",
    "    def match_runways_to_hex(df_low, apt_det_id, apt):\n",
    "\n",
    "        df_single = df_low[df_low['apt_det_id'] == apt_det_id]\n",
    "\n",
    "        core_cols_single = ['apt_det_id', 'id', 'time', 'lat', 'lon', 'hex_id_11', 'baroaltitude_fl']\n",
    "\n",
    "        df_single = df_single[core_cols_single]\n",
    "        df_single = df_single.reset_index()\n",
    "\n",
    "        core_cols_rwy = ['id', 'airport_ref', 'airport_ident', 'gate_id', 'hex_id', 'gate_id_nr','le_ident','he_ident']\n",
    "\n",
    "        df_rwys = pd.read_parquet(f'../data/runway_hex/{apt}.parquet')\n",
    "        df_rwys = df_rwys[core_cols_rwy]\n",
    "\n",
    "        df_hex_rwy = df_single.merge(df_rwys,left_on='hex_id_11', right_on='hex_id', how='left')\n",
    "\n",
    "        result = df_hex_rwy.groupby(['apt_det_id', 'id_x','airport_ident', 'gate_id','le_ident','he_ident'])['time'].agg([min,max]).reset_index().sort_values('min')\n",
    "        return result\n",
    "\n",
    "    dfs = apt_detections_df.apply(lambda l: match_runways_to_hex(result_df, l['apt_det_id'],l['apt_det_ident']),axis=1).to_list()\n",
    "\n",
    "    result = pd.concat(dfs)\n",
    "    return result\n",
    "\n",
    "def identify_runways(df, track_id_col = 'id', longitude_col = 'lon', latitude_col = 'lat', baroaltitude_col = 'baroaltitude'):\n",
    "    \n",
    "    df_w_id = add_statevector_id(df)\n",
    "    \n",
    "    df_w_hex = add_hex_ids(df_w_id, longitude_col=longitude_col, latitude_col=latitude_col,  resolutions=[5, 11])\n",
    "    \n",
    "    df_w_baroalt_ft_fl = convert_baroalt_in_m_to_ft_and_FL(df_w_hex, baroaltitude_col = baroaltitude_col)\n",
    "    \n",
    "    df_f_low_alt = filter_low_altitude_statevectors(df_w_baroalt_ft_fl, baroalt_ft_col = 'baroaltitude_ft', threshold=5000)\n",
    "    \n",
    "    apt_detections_df = identify_potential_airports(df_f_low_alt, track_id_col = track_id_col, hex_id_col='hex_id', apt_types = ['large_airport'])\n",
    "    \n",
    "    rwy_detections_df = identify_runways_from_low_trajectories(apt_detections_df,df_f_low_alt)\n",
    "    \n",
    "    return rwy_detections_df\n",
    "    \n",
    "# Trajectories\n",
    "df = pd.read_parquet('../data/2023-08-02-11.parquet')\n",
    "df['id'] = df['icao24'] + '-' + df['callsign'] + '-' + df['time'].dt.date.apply(str)\n",
    "df = df[['id', 'time', 'icao24', 'callsign', 'lat', 'lon', 'baroaltitude']]\n",
    "\n",
    "rwy_detections_df = identify_runways(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "00cb4216-9b04-4507-a445-a0994b470130",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>apt_det_id</th>\n",
       "      <th>id_x</th>\n",
       "      <th>airport_ident</th>\n",
       "      <th>gate_id</th>\n",
       "      <th>le_ident</th>\n",
       "      <th>he_ident</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>405a46-BAW904N-2023-08-02_0</td>\n",
       "      <td>405a46-BAW904N-2023-08-02</td>\n",
       "      <td>EGLL</td>\n",
       "      <td>runway_hexagons</td>\n",
       "      <td>09R</td>\n",
       "      <td>27L</td>\n",
       "      <td>2023-08-02 11:21:46+00:00</td>\n",
       "      <td>2023-08-02 11:22:01+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>405a46-BAW904N-2023-08-02_0</td>\n",
       "      <td>405a46-BAW904N-2023-08-02</td>\n",
       "      <td>EGLL</td>\n",
       "      <td>high_numbered_approach_hexagons_1_nm</td>\n",
       "      <td>09R</td>\n",
       "      <td>27L</td>\n",
       "      <td>2023-08-02 11:22:02+00:00</td>\n",
       "      <td>2023-08-02 11:22:24+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>405a46-BAW904N-2023-08-02_0</td>\n",
       "      <td>405a46-BAW904N-2023-08-02</td>\n",
       "      <td>EGLL</td>\n",
       "      <td>high_numbered_approach_hexagons_2_nm</td>\n",
       "      <td>09R</td>\n",
       "      <td>27L</td>\n",
       "      <td>2023-08-02 11:22:25+00:00</td>\n",
       "      <td>2023-08-02 11:22:29+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>407463-SHT7C-2023-08-02_1</td>\n",
       "      <td>407463-SHT7C-2023-08-02</td>\n",
       "      <td>EGLL</td>\n",
       "      <td>low_numbered_approach_hexagons_10_nm</td>\n",
       "      <td>09L</td>\n",
       "      <td>27R</td>\n",
       "      <td>2023-08-02 11:12:29+00:00</td>\n",
       "      <td>2023-08-02 11:12:53+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>407463-SHT7C-2023-08-02_1</td>\n",
       "      <td>407463-SHT7C-2023-08-02</td>\n",
       "      <td>EGLL</td>\n",
       "      <td>low_numbered_approach_hexagons_9_nm</td>\n",
       "      <td>09L</td>\n",
       "      <td>27R</td>\n",
       "      <td>2023-08-02 11:12:54+00:00</td>\n",
       "      <td>2023-08-02 11:13:17+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aaba9a-UAL919-2023-08-02_82</td>\n",
       "      <td>aaba9a-UAL919-2023-08-02</td>\n",
       "      <td>EGLL</td>\n",
       "      <td>high_numbered_approach_hexagons_2_nm</td>\n",
       "      <td>09L</td>\n",
       "      <td>27R</td>\n",
       "      <td>2023-08-02 11:37:14+00:00</td>\n",
       "      <td>2023-08-02 11:37:14+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aaba9a-UAL919-2023-08-02_82</td>\n",
       "      <td>aaba9a-UAL919-2023-08-02</td>\n",
       "      <td>EGLL</td>\n",
       "      <td>high_numbered_approach_hexagons_3_nm</td>\n",
       "      <td>09L</td>\n",
       "      <td>27R</td>\n",
       "      <td>2023-08-02 11:37:15+00:00</td>\n",
       "      <td>2023-08-02 11:37:25+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>40087c-BAW5HL-2023-08-02_83</td>\n",
       "      <td>40087c-BAW5HL-2023-08-02</td>\n",
       "      <td>EGLL</td>\n",
       "      <td>runway_hexagons</td>\n",
       "      <td>09R</td>\n",
       "      <td>27L</td>\n",
       "      <td>2023-08-02 11:35:17+00:00</td>\n",
       "      <td>2023-08-02 11:35:33+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40087c-BAW5HL-2023-08-02_83</td>\n",
       "      <td>40087c-BAW5HL-2023-08-02</td>\n",
       "      <td>EGLL</td>\n",
       "      <td>high_numbered_approach_hexagons_1_nm</td>\n",
       "      <td>09R</td>\n",
       "      <td>27L</td>\n",
       "      <td>2023-08-02 11:35:34+00:00</td>\n",
       "      <td>2023-08-02 11:35:58+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>40087c-BAW5HL-2023-08-02_83</td>\n",
       "      <td>40087c-BAW5HL-2023-08-02</td>\n",
       "      <td>EGLL</td>\n",
       "      <td>high_numbered_approach_hexagons_2_nm</td>\n",
       "      <td>09R</td>\n",
       "      <td>27L</td>\n",
       "      <td>2023-08-02 11:35:59+00:00</td>\n",
       "      <td>2023-08-02 11:36:12+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>542 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     apt_det_id                       id_x airport_ident                               gate_id le_ident he_ident                       min                       max\n",
       "2   405a46-BAW904N-2023-08-02_0  405a46-BAW904N-2023-08-02          EGLL                       runway_hexagons      09R      27L 2023-08-02 11:21:46+00:00 2023-08-02 11:22:01+00:00\n",
       "0   405a46-BAW904N-2023-08-02_0  405a46-BAW904N-2023-08-02          EGLL  high_numbered_approach_hexagons_1_nm      09R      27L 2023-08-02 11:22:02+00:00 2023-08-02 11:22:24+00:00\n",
       "1   405a46-BAW904N-2023-08-02_0  405a46-BAW904N-2023-08-02          EGLL  high_numbered_approach_hexagons_2_nm      09R      27L 2023-08-02 11:22:25+00:00 2023-08-02 11:22:29+00:00\n",
       "0     407463-SHT7C-2023-08-02_1    407463-SHT7C-2023-08-02          EGLL  low_numbered_approach_hexagons_10_nm      09L      27R 2023-08-02 11:12:29+00:00 2023-08-02 11:12:53+00:00\n",
       "9     407463-SHT7C-2023-08-02_1    407463-SHT7C-2023-08-02          EGLL   low_numbered_approach_hexagons_9_nm      09L      27R 2023-08-02 11:12:54+00:00 2023-08-02 11:13:17+00:00\n",
       "..                          ...                        ...           ...                                   ...      ...      ...                       ...                       ...\n",
       "1   aaba9a-UAL919-2023-08-02_82   aaba9a-UAL919-2023-08-02          EGLL  high_numbered_approach_hexagons_2_nm      09L      27R 2023-08-02 11:37:14+00:00 2023-08-02 11:37:14+00:00\n",
       "2   aaba9a-UAL919-2023-08-02_82   aaba9a-UAL919-2023-08-02          EGLL  high_numbered_approach_hexagons_3_nm      09L      27R 2023-08-02 11:37:15+00:00 2023-08-02 11:37:25+00:00\n",
       "2   40087c-BAW5HL-2023-08-02_83   40087c-BAW5HL-2023-08-02          EGLL                       runway_hexagons      09R      27L 2023-08-02 11:35:17+00:00 2023-08-02 11:35:33+00:00\n",
       "0   40087c-BAW5HL-2023-08-02_83   40087c-BAW5HL-2023-08-02          EGLL  high_numbered_approach_hexagons_1_nm      09R      27L 2023-08-02 11:35:34+00:00 2023-08-02 11:35:58+00:00\n",
       "1   40087c-BAW5HL-2023-08-02_83   40087c-BAW5HL-2023-08-02          EGLL  high_numbered_approach_hexagons_2_nm      09R      27L 2023-08-02 11:35:59+00:00 2023-08-02 11:36:12+00:00\n",
       "\n",
       "[542 rows x 8 columns]"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rwy_detections_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "f3a39efb-cefe-4509-80ef-1f0c2703dbb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>apt_det_id</th>\n",
       "      <th>id_x</th>\n",
       "      <th>airport_ident</th>\n",
       "      <th>gate_id</th>\n",
       "      <th>le_ident</th>\n",
       "      <th>he_ident</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>405a46-BAW904N-2023-08-02_0</td>\n",
       "      <td>405a46-BAW904N-2023-08-02</td>\n",
       "      <td>EGLL</td>\n",
       "      <td>runway_hexagons</td>\n",
       "      <td>09R</td>\n",
       "      <td>27L</td>\n",
       "      <td>2023-08-02 11:21:46+00:00</td>\n",
       "      <td>2023-08-02 11:22:01+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>405a46-BAW904N-2023-08-02_0</td>\n",
       "      <td>405a46-BAW904N-2023-08-02</td>\n",
       "      <td>EGLL</td>\n",
       "      <td>high_numbered_approach_hexagons_1_nm</td>\n",
       "      <td>09R</td>\n",
       "      <td>27L</td>\n",
       "      <td>2023-08-02 11:22:02+00:00</td>\n",
       "      <td>2023-08-02 11:22:24+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>405a46-BAW904N-2023-08-02_0</td>\n",
       "      <td>405a46-BAW904N-2023-08-02</td>\n",
       "      <td>EGLL</td>\n",
       "      <td>high_numbered_approach_hexagons_2_nm</td>\n",
       "      <td>09R</td>\n",
       "      <td>27L</td>\n",
       "      <td>2023-08-02 11:22:25+00:00</td>\n",
       "      <td>2023-08-02 11:22:29+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>407463-SHT7C-2023-08-02_1</td>\n",
       "      <td>407463-SHT7C-2023-08-02</td>\n",
       "      <td>EGLL</td>\n",
       "      <td>low_numbered_approach_hexagons_10_nm</td>\n",
       "      <td>09L</td>\n",
       "      <td>27R</td>\n",
       "      <td>2023-08-02 11:12:29+00:00</td>\n",
       "      <td>2023-08-02 11:12:53+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>407463-SHT7C-2023-08-02_1</td>\n",
       "      <td>407463-SHT7C-2023-08-02</td>\n",
       "      <td>EGLL</td>\n",
       "      <td>low_numbered_approach_hexagons_9_nm</td>\n",
       "      <td>09L</td>\n",
       "      <td>27R</td>\n",
       "      <td>2023-08-02 11:12:54+00:00</td>\n",
       "      <td>2023-08-02 11:13:17+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aaba9a-UAL919-2023-08-02_82</td>\n",
       "      <td>aaba9a-UAL919-2023-08-02</td>\n",
       "      <td>EGLL</td>\n",
       "      <td>high_numbered_approach_hexagons_2_nm</td>\n",
       "      <td>09L</td>\n",
       "      <td>27R</td>\n",
       "      <td>2023-08-02 11:37:14+00:00</td>\n",
       "      <td>2023-08-02 11:37:14+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aaba9a-UAL919-2023-08-02_82</td>\n",
       "      <td>aaba9a-UAL919-2023-08-02</td>\n",
       "      <td>EGLL</td>\n",
       "      <td>high_numbered_approach_hexagons_3_nm</td>\n",
       "      <td>09L</td>\n",
       "      <td>27R</td>\n",
       "      <td>2023-08-02 11:37:15+00:00</td>\n",
       "      <td>2023-08-02 11:37:25+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>40087c-BAW5HL-2023-08-02_83</td>\n",
       "      <td>40087c-BAW5HL-2023-08-02</td>\n",
       "      <td>EGLL</td>\n",
       "      <td>runway_hexagons</td>\n",
       "      <td>09R</td>\n",
       "      <td>27L</td>\n",
       "      <td>2023-08-02 11:35:17+00:00</td>\n",
       "      <td>2023-08-02 11:35:33+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40087c-BAW5HL-2023-08-02_83</td>\n",
       "      <td>40087c-BAW5HL-2023-08-02</td>\n",
       "      <td>EGLL</td>\n",
       "      <td>high_numbered_approach_hexagons_1_nm</td>\n",
       "      <td>09R</td>\n",
       "      <td>27L</td>\n",
       "      <td>2023-08-02 11:35:34+00:00</td>\n",
       "      <td>2023-08-02 11:35:58+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>40087c-BAW5HL-2023-08-02_83</td>\n",
       "      <td>40087c-BAW5HL-2023-08-02</td>\n",
       "      <td>EGLL</td>\n",
       "      <td>high_numbered_approach_hexagons_2_nm</td>\n",
       "      <td>09R</td>\n",
       "      <td>27L</td>\n",
       "      <td>2023-08-02 11:35:59+00:00</td>\n",
       "      <td>2023-08-02 11:36:12+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>542 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     apt_det_id                       id_x airport_ident                               gate_id le_ident he_ident                       min                       max\n",
       "2   405a46-BAW904N-2023-08-02_0  405a46-BAW904N-2023-08-02          EGLL                       runway_hexagons      09R      27L 2023-08-02 11:21:46+00:00 2023-08-02 11:22:01+00:00\n",
       "0   405a46-BAW904N-2023-08-02_0  405a46-BAW904N-2023-08-02          EGLL  high_numbered_approach_hexagons_1_nm      09R      27L 2023-08-02 11:22:02+00:00 2023-08-02 11:22:24+00:00\n",
       "1   405a46-BAW904N-2023-08-02_0  405a46-BAW904N-2023-08-02          EGLL  high_numbered_approach_hexagons_2_nm      09R      27L 2023-08-02 11:22:25+00:00 2023-08-02 11:22:29+00:00\n",
       "0     407463-SHT7C-2023-08-02_1    407463-SHT7C-2023-08-02          EGLL  low_numbered_approach_hexagons_10_nm      09L      27R 2023-08-02 11:12:29+00:00 2023-08-02 11:12:53+00:00\n",
       "9     407463-SHT7C-2023-08-02_1    407463-SHT7C-2023-08-02          EGLL   low_numbered_approach_hexagons_9_nm      09L      27R 2023-08-02 11:12:54+00:00 2023-08-02 11:13:17+00:00\n",
       "..                          ...                        ...           ...                                   ...      ...      ...                       ...                       ...\n",
       "1   aaba9a-UAL919-2023-08-02_82   aaba9a-UAL919-2023-08-02          EGLL  high_numbered_approach_hexagons_2_nm      09L      27R 2023-08-02 11:37:14+00:00 2023-08-02 11:37:14+00:00\n",
       "2   aaba9a-UAL919-2023-08-02_82   aaba9a-UAL919-2023-08-02          EGLL  high_numbered_approach_hexagons_3_nm      09L      27R 2023-08-02 11:37:15+00:00 2023-08-02 11:37:25+00:00\n",
       "2   40087c-BAW5HL-2023-08-02_83   40087c-BAW5HL-2023-08-02          EGLL                       runway_hexagons      09R      27L 2023-08-02 11:35:17+00:00 2023-08-02 11:35:33+00:00\n",
       "0   40087c-BAW5HL-2023-08-02_83   40087c-BAW5HL-2023-08-02          EGLL  high_numbered_approach_hexagons_1_nm      09R      27L 2023-08-02 11:35:34+00:00 2023-08-02 11:35:58+00:00\n",
       "1   40087c-BAW5HL-2023-08-02_83   40087c-BAW5HL-2023-08-02          EGLL  high_numbered_approach_hexagons_2_nm      09R      27L 2023-08-02 11:35:59+00:00 2023-08-02 11:36:12+00:00\n",
       "\n",
       "[542 rows x 8 columns]"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rwy_detections_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "b3ad76a3-2528-4f69-8df8-47f4e2326c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = rwy_detections_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "9a55dc7a-0edd-453d-8c0e-3e60f010e449",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_392/3964797399.py:109: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  rwy_winner = rwy_winner.groupby(['id_x', 'apt_det_id', 'airport_ident'])['le_ident', 'he_ident', 'rwy','score', 'status'].agg(', '.join).reset_index()\n"
     ]
    }
   ],
   "source": [
    "def clean_gate(gate_id):\n",
    "    if gate_id == 'runway_hexagons':\n",
    "        return 'runway_hexagons',0\n",
    "    else:\n",
    "        return '_'.join(gate_id.split('_')[:4]), int(gate_id.split('_')[4])\n",
    "\n",
    "result['gate_type'], result['gate_distance_from_rwy_nm'] = zip(*result.gate_id.apply(clean_gate))\n",
    "\n",
    "## Determining arrival / departure... \n",
    "\n",
    "result = result.reset_index(drop=True)\n",
    "\n",
    "result_min = result.loc[result.groupby(['id_x', 'apt_det_id', 'airport_ident', 'le_ident', 'he_ident'])['gate_distance_from_rwy_nm'].idxmin()]\n",
    "result_max = result.loc[result.groupby(['id_x', 'apt_det_id', 'airport_ident', 'le_ident', 'he_ident'])['gate_distance_from_rwy_nm'].idxmax()] \n",
    "\n",
    "# Copy the DataFrame to avoid modifying the original unintentionally\n",
    "result_copy = result.copy()\n",
    "\n",
    "# Compute the minimum and maximum 'gate_distance_from_rwy_nm' for each group\n",
    "min_values = result.groupby(['id_x', 'apt_det_id', 'airport_ident', 'le_ident', 'he_ident'])['gate_distance_from_rwy_nm'].transform('min')\n",
    "max_values = result.groupby(['id_x', 'apt_det_id', 'airport_ident', 'le_ident', 'he_ident'])['gate_distance_from_rwy_nm'].transform('max')\n",
    "\n",
    "# Add these as new columns to the DataFrame\n",
    "result_copy['min_gate_distance'] = min_values\n",
    "result_copy['max_gate_distance'] = max_values\n",
    "\n",
    "# Now, you can filter rows where 'gate_distance_from_rwy_nm' matches the min or max values\n",
    "# To specifically keep rows with the minimum value:\n",
    "result_min = result_copy[result_copy['gate_distance_from_rwy_nm'] == result_copy['min_gate_distance']]\n",
    "\n",
    "# To specifically keep rows with the maximum value:\n",
    "result_max = result_copy[result_copy['gate_distance_from_rwy_nm'] == result_copy['max_gate_distance']]\n",
    "\n",
    "\n",
    "cols_of_interest = ['id_x', 'apt_det_id', 'airport_ident', 'le_ident', 'he_ident', 'min', 'gate_distance_from_rwy_nm']\n",
    "result_min = result_min[cols_of_interest].rename({'min':'time_entry_min_distance', 'gate_distance_from_rwy_nm':'min_gate_distance_from_rwy_nm'},axis=1)\n",
    "result_max = result_max[cols_of_interest].rename({'min':'time_entry_max_distance', 'gate_distance_from_rwy_nm':'max_gate_distance_from_rwy_nm'},axis=1)\n",
    "\n",
    "det = result_min.merge(result_max, on=['id_x', 'apt_det_id', 'airport_ident', 'le_ident', 'he_ident'], how='outer')\n",
    "\n",
    "det['time_since_minimum_distance'] = det['time_entry_min_distance']-det['time_entry_max_distance']\n",
    "\n",
    "det['time_since_minimum_distance_s'] = det['time_since_minimum_distance'].dt.total_seconds()\n",
    "\n",
    "det['status'] = det['time_since_minimum_distance_s'].apply(lambda l: 'arrival' if l > 0 else 'departure')\n",
    "det['status'] = det['status'].fillna('undetermined')\n",
    "\n",
    "det = det[['id_x', 'apt_det_id', 'airport_ident', 'le_ident', 'he_ident','status']]\n",
    "\n",
    "gb_cols = ['id_x', 'apt_det_id', 'airport_ident', 'le_ident', 'he_ident', 'gate_type']\n",
    "result = result.groupby(gb_cols).agg(\n",
    "    entry_time_approach_area=('min', 'min'),\n",
    "    exit_time_approach_area=('max', 'max'),\n",
    "    intersected_subsections=('gate_distance_from_rwy_nm', 'count'),\n",
    "    minimal_distance_runway=('gate_distance_from_rwy_nm', 'min'),\n",
    "    maximal_distance_runway=('gate_distance_from_rwy_nm', 'max')\n",
    ")\n",
    "result = result.reset_index()\n",
    "\n",
    "rwy_result_cols = ['id_x', 'apt_det_id', 'airport_ident', 'le_ident', 'he_ident']\n",
    "\n",
    "rwy_result = result[rwy_result_cols + ['gate_type']]\n",
    "rwy_result = rwy_result[rwy_result['gate_type']=='runway_hexagons']\n",
    "rwy_result = rwy_result[rwy_result_cols]\n",
    "rwy_result['runway_detected'] = True\n",
    "\n",
    "result = result.merge(rwy_result, on=rwy_result_cols, how = 'left')\n",
    "\n",
    "result['runway_detected'] = result['runway_detected'].fillna(False)\n",
    "\n",
    "result = result[result['gate_type']!='runway_hexagons']\n",
    "\n",
    "result['high_number_intersections'] = result['intersected_subsections']>5\n",
    "\n",
    "result['low_minimal_distance'] = result['minimal_distance_runway']<5\n",
    "\n",
    "result['touched_closest_segment_to_rw'] = result['minimal_distance_runway']==1\n",
    "\n",
    "result['touched_second_closest_segment_to_rw'] = result['minimal_distance_runway']<=2 \n",
    "\n",
    "approach_detected_weight = 0.3\n",
    "rwy_detected_weight = 2\n",
    "high_number_intersections_weight = 1 \n",
    "low_minimal_distance_weight = 1\n",
    "touched_closest_segment_to_rw_weight = 1.5\n",
    "touched_second_closest_segment_to_rw_weight = 0.75\n",
    "\n",
    "max_score = approach_detected_weight + rwy_detected_weight + high_number_intersections_weight + low_minimal_distance_weight + touched_closest_segment_to_rw_weight + touched_second_closest_segment_to_rw_weight\n",
    "\n",
    "result['score'] = (\n",
    "                   1*approach_detected_weight + # For all flights in this dataset an approach is detected (i.e., they entered the approach cone)\n",
    "                   result['runway_detected'].apply(int)*rwy_detected_weight + \n",
    "                   result['high_number_intersections'].apply(int)*high_number_intersections_weight + \n",
    "                   result['low_minimal_distance'].apply(int)*touched_closest_segment_to_rw_weight + \n",
    "                   result['touched_closest_segment_to_rw'].apply(int)*touched_closest_segment_to_rw_weight + \n",
    "                   result['touched_second_closest_segment_to_rw'].apply(int)*touched_second_closest_segment_to_rw_weight\n",
    "                  ) / max_score * 100\n",
    "\n",
    "result = result.reset_index(drop=True)\n",
    "\n",
    "result = result.merge(det,on=['id_x', 'apt_det_id', 'airport_ident','le_ident','he_ident'], how ='left')\n",
    "\n",
    "result['status'] = result['status'].fillna('undetermined')\n",
    "\n",
    "result['rwy'] = result['le_ident'] + '/' + result['he_ident']\n",
    "\n",
    "rwy_winner = result.loc[result.groupby(['id_x','apt_det_id','airport_ident'])['score'].idxmax()]\n",
    "rwy_winner['score'] = rwy_winner['score'].apply(str)\n",
    "rwy_winner = rwy_winner.groupby(['id_x', 'apt_det_id', 'airport_ident'])['le_ident', 'he_ident', 'rwy','score', 'status'].agg(', '.join).reset_index()\n",
    "rwy_winner = rwy_winner.rename({\n",
    "    'id_x':'id',\n",
    "    'rwy' : 'likely_rwy',\n",
    "    'score': 'likely_rwy_score',\n",
    "    'status': 'likely_rwy_status'\n",
    "    }, axis=1)\n",
    "\n",
    "id_cols = ['id', 'apt_det_id', 'airport_ident', 'le_ident', 'he_ident']\n",
    "rwy_winner_flag = rwy_winner[id_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "3a5c0771-d540-4203-ac8f-2bceaa042875",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_392/3086322664.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  rwy_winner_flag['winner'] = True\n"
     ]
    }
   ],
   "source": [
    "rwy_winner_flag['winner'] = True\n",
    "\n",
    "result = result.rename({'id_x':'id'}, axis=1)\n",
    "result = result.merge(rwy_winner_flag, on = id_cols, how='left') \n",
    "result['winner'] = result['winner'].fillna(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "ccb780b2-a897-481c-a2ef-365ff5d7b525",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_392/666940012.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  rwy_losers['score'] = rwy_losers['score'].apply(str)\n",
      "/tmp/ipykernel_392/666940012.py:4: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  rwy_losers = rwy_losers.groupby(['id', 'apt_det_id','airport_ident'])['le_ident', 'he_ident', 'rwy','score', 'status'].agg(', '.join).reset_index()\n"
     ]
    }
   ],
   "source": [
    "rwy_losers = result[result['winner']==False]\n",
    "\n",
    "rwy_losers['score'] = rwy_losers['score'].apply(str)\n",
    "rwy_losers = rwy_losers.groupby(['id', 'apt_det_id','airport_ident'])['le_ident', 'he_ident', 'rwy','score', 'status'].agg(', '.join).reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "60e4e7d1-7831-4ba3-9fab-86bfa7c72654",
   "metadata": {},
   "outputs": [],
   "source": [
    "rwy_losers = rwy_losers.rename({\n",
    "    'rwy' : 'potential_other_rwys',\n",
    "    'score': 'potential_other_rwy_scores',\n",
    "    'status': 'potential_other_rwy_status'\n",
    "    }, axis=1)[['id','apt_det_id', 'airport_ident', 'potential_other_rwys', 'potential_other_rwy_scores', 'potential_other_rwy_status']]\n",
    "\n",
    "rwy_determined = rwy_winner.merge(rwy_losers, on=['id','apt_det_id','airport_ident'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "a8284332-efd1-4699-ae42-69a0a7588652",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>apt_det_id</th>\n",
       "      <th>airport_ident</th>\n",
       "      <th>le_ident</th>\n",
       "      <th>he_ident</th>\n",
       "      <th>likely_rwy</th>\n",
       "      <th>likely_rwy_score</th>\n",
       "      <th>likely_rwy_status</th>\n",
       "      <th>potential_other_rwys</th>\n",
       "      <th>potential_other_rwy_scores</th>\n",
       "      <th>potential_other_rwy_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0a0048-DAH2054-2023-08-02</td>\n",
       "      <td>0a0048-DAH2054-2023-08-02_59</td>\n",
       "      <td>EGLL</td>\n",
       "      <td>09L</td>\n",
       "      <td>27R</td>\n",
       "      <td>09L/27R</td>\n",
       "      <td>77.09923664122137</td>\n",
       "      <td>arrival</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3472cc-IBE31ZZ-2023-08-02</td>\n",
       "      <td>3472cc-IBE31ZZ-2023-08-02_11</td>\n",
       "      <td>EGLL</td>\n",
       "      <td>09R</td>\n",
       "      <td>27L</td>\n",
       "      <td>09R/27L</td>\n",
       "      <td>92.36641221374046</td>\n",
       "      <td>departure</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>39e684-AFR79ZE-2023-08-02</td>\n",
       "      <td>39e684-AFR79ZE-2023-08-02_79</td>\n",
       "      <td>LFPG</td>\n",
       "      <td>08L</td>\n",
       "      <td>26R</td>\n",
       "      <td>08L/26R</td>\n",
       "      <td>42.74809160305343</td>\n",
       "      <td>arrival</td>\n",
       "      <td>08R/26L</td>\n",
       "      <td>38.93129770992366</td>\n",
       "      <td>arrival</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3c00af-KAY51-2023-08-02</td>\n",
       "      <td>3c00af-KAY51-2023-08-02_31</td>\n",
       "      <td>EGLL</td>\n",
       "      <td>09R</td>\n",
       "      <td>27L</td>\n",
       "      <td>09R/27L</td>\n",
       "      <td>92.36641221374046</td>\n",
       "      <td>departure</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3c65cb-DLH5U-2023-08-02</td>\n",
       "      <td>3c65cb-DLH5U-2023-08-02_38</td>\n",
       "      <td>EGLL</td>\n",
       "      <td>09R</td>\n",
       "      <td>27L</td>\n",
       "      <td>09R/27L</td>\n",
       "      <td>92.36641221374046</td>\n",
       "      <td>departure</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>ab60e3-DAL31-2023-08-02</td>\n",
       "      <td>ab60e3-DAL31-2023-08-02_32</td>\n",
       "      <td>EGLL</td>\n",
       "      <td>09R</td>\n",
       "      <td>27L</td>\n",
       "      <td>09R/27L</td>\n",
       "      <td>61.832061068702295</td>\n",
       "      <td>departure</td>\n",
       "      <td>09L/27R</td>\n",
       "      <td>38.93129770992366</td>\n",
       "      <td>departure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>ab79ca-AAL47-2023-08-02</td>\n",
       "      <td>ab79ca-AAL47-2023-08-02_33</td>\n",
       "      <td>EGLL</td>\n",
       "      <td>09R</td>\n",
       "      <td>27L</td>\n",
       "      <td>09R/27L</td>\n",
       "      <td>92.36641221374046</td>\n",
       "      <td>departure</td>\n",
       "      <td>09L/27R</td>\n",
       "      <td>38.93129770992366</td>\n",
       "      <td>departure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>c0103a-ACA903-2023-08-02</td>\n",
       "      <td>c0103a-ACA903-2023-08-02_5</td>\n",
       "      <td>EGLL</td>\n",
       "      <td>09R</td>\n",
       "      <td>27L</td>\n",
       "      <td>09R/27L</td>\n",
       "      <td>61.832061068702295</td>\n",
       "      <td>departure</td>\n",
       "      <td>09L/27R</td>\n",
       "      <td>38.93129770992366</td>\n",
       "      <td>departure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>c01723-ACA858-2023-08-02</td>\n",
       "      <td>c01723-ACA858-2023-08-02_36</td>\n",
       "      <td>EGLL</td>\n",
       "      <td>09L</td>\n",
       "      <td>27R</td>\n",
       "      <td>09L/27R</td>\n",
       "      <td>61.832061068702295</td>\n",
       "      <td>arrival</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>c0656f-WJA18-2023-08-02</td>\n",
       "      <td>c0656f-WJA18-2023-08-02_24</td>\n",
       "      <td>EGLL</td>\n",
       "      <td>09L</td>\n",
       "      <td>27R</td>\n",
       "      <td>09L/27R</td>\n",
       "      <td>77.09923664122137</td>\n",
       "      <td>arrival</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>83 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           id                    apt_det_id airport_ident le_ident he_ident likely_rwy    likely_rwy_score likely_rwy_status potential_other_rwys potential_other_rwy_scores potential_other_rwy_status\n",
       "0   0a0048-DAH2054-2023-08-02  0a0048-DAH2054-2023-08-02_59          EGLL      09L      27R    09L/27R   77.09923664122137           arrival                  NaN                        NaN                        NaN\n",
       "1   3472cc-IBE31ZZ-2023-08-02  3472cc-IBE31ZZ-2023-08-02_11          EGLL      09R      27L    09R/27L   92.36641221374046         departure                  NaN                        NaN                        NaN\n",
       "2   39e684-AFR79ZE-2023-08-02  39e684-AFR79ZE-2023-08-02_79          LFPG      08L      26R    08L/26R   42.74809160305343           arrival              08R/26L          38.93129770992366                    arrival\n",
       "3     3c00af-KAY51-2023-08-02    3c00af-KAY51-2023-08-02_31          EGLL      09R      27L    09R/27L   92.36641221374046         departure                  NaN                        NaN                        NaN\n",
       "4     3c65cb-DLH5U-2023-08-02    3c65cb-DLH5U-2023-08-02_38          EGLL      09R      27L    09R/27L   92.36641221374046         departure                  NaN                        NaN                        NaN\n",
       "..                        ...                           ...           ...      ...      ...        ...                 ...               ...                  ...                        ...                        ...\n",
       "78    ab60e3-DAL31-2023-08-02    ab60e3-DAL31-2023-08-02_32          EGLL      09R      27L    09R/27L  61.832061068702295         departure              09L/27R          38.93129770992366                  departure\n",
       "79    ab79ca-AAL47-2023-08-02    ab79ca-AAL47-2023-08-02_33          EGLL      09R      27L    09R/27L   92.36641221374046         departure              09L/27R          38.93129770992366                  departure\n",
       "80   c0103a-ACA903-2023-08-02    c0103a-ACA903-2023-08-02_5          EGLL      09R      27L    09R/27L  61.832061068702295         departure              09L/27R          38.93129770992366                  departure\n",
       "81   c01723-ACA858-2023-08-02   c01723-ACA858-2023-08-02_36          EGLL      09L      27R    09L/27R  61.832061068702295           arrival                  NaN                        NaN                        NaN\n",
       "82    c0656f-WJA18-2023-08-02    c0656f-WJA18-2023-08-02_24          EGLL      09L      27R    09L/27R   77.09923664122137           arrival                  NaN                        NaN                        NaN\n",
       "\n",
       "[83 rows x 11 columns]"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rwy_determined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c5dda9-0e03-4e1a-b920-c30d0b3cde0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d72d238-2350-45de-b960-51e5d77f9d77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b87b172-a9a4-4f2a-b670-68a979e0d54e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d83dcc94-6e0a-4780-a3c8-3534d003db47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c01541-aba6-416d-8f18-415d010e6f6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "099edccc-c7ea-408c-b8b5-3df38a64bac6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab616670-3afd-4fa7-9870-17f8bb09089b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9664af76-577f-41f0-84e1-1a9a13d276e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d4c1174-b022-45b9-813d-2b6b971f4b63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4490e9b2-efca-4e5d-8b05-016b15f5e923",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde2be93-9d2c-47fb-9258-a0593dadfe5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dadc9fd-7b23-4999-93a7-f683daf05d64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbcc44ee-5b00-4b4c-8377-5ed3cf01fe19",
   "metadata": {},
   "outputs": [],
   "source": [
    "rwy_winner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f1ef0d-230a-4d93-9e4e-a9b5ec45d37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rwy_losers['score'] = rwy_losers['score'].apply(str)\n",
    "\n",
    "rwy_losers.groupby(['id_x','airport_ident'])['rwy','score'].agg(', '.join)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d60dab9-0dd6-4bcf-ba28-778ca3983907",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.id_x.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62d4b56-16ff-450d-9fc8-b183ed27931e",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.groupby()[''].agg(max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e4fa86d-77ae-4459-aa9d-3cae696ae4d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "result['minimal_dist_rwy_<_5nm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f07ab7c-0a7b-48ef-bfc1-a06f4a61f4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "result[result['id_x']=='4009d8-BAW3ET-2023-08-02']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce69300-5c7e-4b89-b3b9-bd19808b643a",
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37bc2deb-5e45-4ff0-bca3-229bb9700145",
   "metadata": {},
   "outputs": [],
   "source": [
    "result['id_x'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "534c383d-0139-492d-a5bd-8de99a98d02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_cols = ['id_x','airport_ident','le_ident','he_ident','gate_type']\n",
    "result.groupby(gb_cols)['min','max','gate_distance_from_rwy_nm'].agg(['count', min, max])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b30be20-6207-494e-9257-f97cb4f7d58a",
   "metadata": {},
   "outputs": [],
   "source": [
    "result['type_gate'] = result.gate_id.apply(lambda l:)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f9a757-3962-4742-a734-e729b4be6073",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat(,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4089aa5-80cd-41d0-a0ef-855d3da19889",
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40f2e0b-7996-4675-b1ae-e52722215900",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee360f5d-c273-4410-8fcf-c35de96c19f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d237234f-a763-4416-b572-491a5bfb49d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#res_gb = res_gb.explode('ident')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5358a224-fd8e-44f3-9146-0f7b93766478",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_m = df_f.merge(res_gb, left_on='id', right_on='id_x', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb215a12-7977-4600-bcdd-82eb193e6854",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_m['ident']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f08fa2b4-5fea-418a-a29e-9424d7cf5c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "px.line(df[df['id'].isin(ids)], x='time', y='baroaltitude_fl', color='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc27025b-edc5-4716-80f0-39f61f7c3e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h3_viz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed0b455-4e24-4287-8602-b27881f39e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "latitude = apt_hex['latitude_deg'].values[0]\n",
    "longitude = apt_hex['longitude_deg'].values[0]\n",
    "\n",
    "m = h3_viz.choropleth_map(\n",
    "        apt_hex,\n",
    "        column_name='elevation_ft',\n",
    "        border_color='black',\n",
    "        fill_opacity=0.7,\n",
    "        color_map_name='Reds',\n",
    "        initial_map=None,\n",
    "        initial_location=[latitude, longitude],\n",
    "        initial_zoom = 14,\n",
    "        tooltip_columns = ['ident', 'latitude_deg', 'longitude_deg']\n",
    ")\n",
    "\n",
    "m#.save('airport_hex.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "600a46f2-7b5a-4783-9278-9043eeab11f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import udf,from_unixtime, min, max, to_date, pandas_udf, col, PandasUDFType, lit, round\n",
    "from pyspark.sql.types import DoubleType, ArrayType, StructType, StructField, StringType\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql import Window\n",
    "\n",
    "import os, time\n",
    "import subprocess\n",
    "import os,shutil\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "import requests\n",
    "from shapely.geometry import LineString, Polygon\n",
    "from shapely.ops import transform\n",
    "import pyproj\n",
    "from functools import partial\n",
    "from shapely.geometry import LineString\n",
    "from shapely.ops import transform\n",
    "from pyproj import Proj, Transformer\n",
    "import pandas as pd\n",
    "import folium\n",
    "from shapely.geometry import Polygon\n",
    "from shapely.ops import unary_union\n",
    "import shapely.geometry\n",
    "import h3\n",
    "import h3_viz\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Settings\n",
    "project = \"project_aiu\"\n",
    "\n",
    "\n",
    "# Getting today's date\n",
    "today = datetime.today().strftime('%d %B %Y')\n",
    "\n",
    "# Spark Session Initialization\n",
    "shutil.copy(\"/runtime-addons/cmladdon-2.0.40-b150/log4j.properties\", \"/etc/spark/conf/\") # Setting logging properties\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"OSN ADEP ADES Identification\") \\\n",
    "    .config(\"spark.log.level\", \"ERROR\")\\\n",
    "    .config(\"spark.hadoop.fs.azure.ext.cab.required.group\", \"eur-app-aiu-dev\") \\\n",
    "    .config(\"spark.kerberos.access.hadoopFileSystems\", \"abfs://storage-fs@cdpdldev0.dfs.core.windows.net/data/project/aiu.db/unmanaged\") \\\n",
    "    .config(\"spark.driver.cores\", \"1\") \\\n",
    "    .config(\"spark.driver.memory\", \"8G\") \\\n",
    "    .config(\"spark.executor.memory\", \"5G\") \\\n",
    "    .config(\"spark.executor.cores\", \"1\") \\\n",
    "    .config(\"spark.executor.instances\", \"2\") \\\n",
    "    .config(\"spark.dynamicAllocation.maxExecutors\", \"6\") \\\n",
    "    .config(\"spark.network.timeout\", \"800s\") \\\n",
    "    .config(\"spark.executor.heartbeatInterval\", \"400s\") \\\n",
    "    .enableHiveSupport() \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Get environment variables\n",
    "engine_id = os.getenv('CDSW_ENGINE_ID')\n",
    "domain = os.getenv('CDSW_DOMAIN')\n",
    "\n",
    "# Format the URL\n",
    "url = f\"https://spark-{engine_id}.{domain}\"\n",
    "\n",
    "# Display the clickable URL\n",
    "display(HTML(f'<a href=\"{url}\">{url}</a>'))\n",
    "\n",
    "airports_df = spark.sql(f\"\"\"\n",
    "    SELECT id, ident, iso_country, continent, latitude_deg, longitude_deg, elevation_ft, type\n",
    "    FROM {project}.oa_airports\n",
    "    WHERE (ident LIKE 'E%' OR ident LIKE 'L%' OR ident LIKE 'U%')\n",
    "    AND (type = 'large_airport' OR type = 'medium_airport');\n",
    "\"\"\")\n",
    "\n",
    "import math\n",
    "import json\n",
    "\n",
    "def generate_circle_polygon(lat, lon, radius_nautical_miles, num_points=360):\n",
    "    \"\"\"\n",
    "    Generate a polygon in GeoJSON format around a given latitude and longitude\n",
    "    with a specified radius in nautical miles.\n",
    "    \n",
    "    :param lat: Latitude of the center point\n",
    "    :param lon: Longitude of the center point\n",
    "    :param radius_nautical_miles: Radius in nautical miles\n",
    "    :param num_points: Number of points to generate for the polygon\n",
    "    :return: A dictionary representing the polygon in GeoJSON format\n",
    "    \"\"\"\n",
    "    # Convert radius from nautical miles to kilometers\n",
    "    radius_km = radius_nautical_miles * 1.852\n",
    "    \n",
    "    # Function to convert from degrees to radians\n",
    "    def degrees_to_radians(degrees):\n",
    "        return degrees * math.pi / 180\n",
    "    \n",
    "    # Function to calculate the next point given a distance and bearing\n",
    "    def calculate_point(lat, lon, distance_km, bearing):\n",
    "        R = 6371.01  # Earth's radius in kilometers\n",
    "        lat_rad = degrees_to_radians(lat)\n",
    "        lon_rad = degrees_to_radians(lon)\n",
    "        distance_rad = distance_km / R\n",
    "        bearing_rad = degrees_to_radians(bearing)\n",
    "        \n",
    "        lat_new_rad = math.asin(math.sin(lat_rad) * math.cos(distance_rad) +\n",
    "                                math.cos(lat_rad) * math.sin(distance_rad) * math.cos(bearing_rad))\n",
    "        lon_new_rad = lon_rad + math.atan2(math.sin(bearing_rad) * math.sin(distance_rad) * math.cos(lat_rad),\n",
    "                                           math.cos(distance_rad) - math.sin(lat_rad) * math.sin(lat_new_rad))\n",
    "                                           \n",
    "        lat_new = math.degrees(lat_new_rad)\n",
    "        lon_new = math.degrees(lon_new_rad)\n",
    "        return [lon_new, lat_new]\n",
    "    \n",
    "    # Generate points\n",
    "    points = []\n",
    "    for i in range(num_points):\n",
    "        bearing = 360 / num_points * i\n",
    "        point = calculate_point(lat, lon, radius_km, bearing)\n",
    "        points.append(point)\n",
    "    #points.append(points[0])  # Close the polygon by repeating the first point\n",
    "    \n",
    "    # Create GeoJSON\n",
    "    geojson = {\n",
    "        \"type\": \"Polygon\",\n",
    "        \"coordinates\": [points]\n",
    "    }\n",
    "    \n",
    "    geojson_str = json.dumps(geojson)\n",
    "    \n",
    "    return geojson_str\n",
    "\n",
    "def fill_circle_with_hexagons(polygon_json, resolution=8):\n",
    "    polygon = json.loads(polygon_json)\n",
    "    hexagons = h3.polyfill(polygon, resolution, geo_json_conformant=True)\n",
    "    return list(hexagons)\n",
    "\n",
    "import folium\n",
    "from shapely.ops import unary_union\n",
    "\n",
    "geojson = generate_circle_polygon(lat=27.994402, lon=-93, radius_nautical_miles=35, num_points=360)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ccae9f-2a14-4824-8861-475569ea7c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "h3.polyfill?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc242a81-5f89-46cd-9076-ae5cb3abb3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "folium.GeoJson?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ac9a05-383d-454f-b180-7f88a7ed308f",
   "metadata": {},
   "outputs": [],
   "source": [
    "h3.h3_to_geo_boundary?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31689501-773f-4e4f-a43f-f0e442b2feb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "h3.h3_to_geo?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a7a3d9-6e09-4b43-97f8-5bb7f22a36f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "h3.polyfill?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1efc45ff-d32b-4b71-8544-108c08a11f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "hexagons = fill_circle_with_hexagons(geojson, resolution=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc7f3a8-3159-4a5f-bd73-ae7407c99977",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict({'hex_id':hexagons, 'color': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "528a1b9f-4d82-41d8-b356-53c342b1ce6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium\n",
    "folium.GeoJson?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "891f9d8f-d464-48dc-9bf2-606341aa8e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h3\n",
    "h3.h3_to_geo?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d927b15-420a-44c6-be51-f997bf55981a",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = h3_viz.choropleth_map(\n",
    "        df,\n",
    "        column_name='color',\n",
    "        border_color='black',\n",
    "        fill_opacity=0.7,\n",
    "        color_map_name='Reds',\n",
    "        initial_map=None,\n",
    "        initial_location=[latitude, longitude],\n",
    "        initial_zoom = 14,\n",
    "        tooltip_columns = []\n",
    ")\n",
    "\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c7c580f-daaf-4916-a703-636fdfd4b613",
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium\n",
    "import json\n",
    "import h3\n",
    "\n",
    "def plot_hexagons(hexagons, map_object):\n",
    "    \"\"\"\n",
    "    Plot hexagons on a Folium map.\n",
    "\n",
    "    Parameters:\n",
    "    - hexagons: A list of hexagon IDs.\n",
    "    - map_object: A Folium Map object to which the hexagons will be added.\n",
    "    \"\"\"\n",
    "    for hexagon in hexagons:\n",
    "        hex_boundary = h3.h3_to_geo_boundary(hexagon, geo_json=False)\n",
    "        #print(hex_boundary)\n",
    "        #print(hex_boundary)\n",
    "        folium.Polygon(locations=hex_boundary, color=\"blue\", fill=True).add_to(map_object)\n",
    "\n",
    "# Assuming `geojson` contains the circular area and `fill_circle_with_hexagons` has been called appropriately\n",
    "hexagons = fill_circle_with_hexagons(geojson, resolution=8)\n",
    "\n",
    "# Initialize a Folium map at a specific location\n",
    "m = folium.Map(location=[27.994402, -88.760254], zoom_start=6)\n",
    "\n",
    "# Plot the circular area\n",
    "folium.GeoJson(geojson, style_function=lambda x: {'fillColor': 'red', 'color': 'red'}).add_to(m)\n",
    "\n",
    "# Plot hexagons within the circle\n",
    "plot_hexagons(hexagons, m)\n",
    "\n",
    "# Display the map\n",
    "m\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d0abbe1-d0f7-4793-bcdb-29a8946292eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f024ae42-f955-4ccf-9e6e-838760ad89b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(eurocontrol_countries_iso2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c018a0-7d5e-48cb-ad4a-4c7fce5a4338",
   "metadata": {},
   "outputs": [],
   "source": [
    "airports_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ea0d0b-285c-4c0a-9e1c-ee19bc945796",
   "metadata": {},
   "outputs": [],
   "source": [
    "airports_df.continent.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c5f4ac1-ce0c-48fc-a301-4e2a48873ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "airports_df.longitude_deg.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a227b7e-34e1-4e83-92b2-757afce43215",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da8e75c-a7a8-4be6-b364-3c9fc968106d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h3_viz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c46696-2342-4a24-aab1-b60e1ef4cd44",
   "metadata": {},
   "outputs": [],
   "source": [
    "airports_df = pd.read_parquet('../data/airport_hex/airport_hex_res_6.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff538e8a-7562-4b56-92bb-766f0a83d5d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e75d04f-50ea-45f6-af8f-3ce66eba185a",
   "metadata": {},
   "outputs": [],
   "source": [
    "h3.h3_to_geo?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6efd4998-7e43-40e3-b545-378b670cb7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a9a6c4-140c-4e9f-93cd-d2df5da80bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "airports_df['hex_id'].isna().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb06934-d0b6-4d76-a079-a35626427ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "airports_dff = airports_df[~airports_df['hex_id'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af7c42d5-c05e-44a1-bbdb-cee0f2957694",
   "metadata": {},
   "outputs": [],
   "source": [
    "airports_dff.latitude_deg.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260e642c-8214-47e8-8a90-90b58e0875a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "airports_dff.longitude_deg.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a649d2-3b7f-4cb4-bf67-713608daa258",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_viz = h3_viz.choropleth_map(\n",
    "      airports_dff.explode('hex_id'),\n",
    "      column_name='latitude_deg',\n",
    "      border_color='black',\n",
    "      fill_opacity=0.7,\n",
    "      color_map_name='Reds',\n",
    "      initial_map=None,\n",
    "      initial_location=[airports_df.latitude_deg.values[0], airports_df.longitude_deg.values[0]],\n",
    "      initial_zoom = 14,\n",
    "      tooltip_columns = []\n",
    "  )\n",
    "map_viz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf17a99-224c-4654-abca-46c1366ab286",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97492b4a-b3ff-4b47-9fa7-2410433ca072",
   "metadata": {},
   "outputs": [],
   "source": [
    "json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b594692e-2ba7-400c-9437-ed33acdff76a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fill_polygon_with_hexagons()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
